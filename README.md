# Curso de Data Engineering Essentials (SQL, Python, PySpark)

Este repositorio contiene todo el trabajo realizado durante el curso de Udemy **â€œData Engineering Essentials using SQL, Python, and PySparkâ€**. La estructura del repositorio estÃ¡ organizada por Ã¡reas temÃ¡ticas y herramientas utilizadas.

---

## ğŸ“‚ Estructura del proyecto

curso-udemy/
â”œâ”€â”€ sql/ â†’ Consultas SQL y ejercicios
â”‚ â”œâ”€â”€ 01_intro/ â†’ IntroducciÃ³n a SQL
â”‚ â”œâ”€â”€ 02_basic_queries/ â†’ Consultas bÃ¡sicas
â”‚ â”œâ”€â”€ 03_aggregations/ â†’ Agregaciones y ranking
â”‚ â”œâ”€â”€ 04_performance/ â†’ OptimizaciÃ³n de consultas
â”‚ â””â”€â”€ exercises/ â†’ Ejercicios prÃ¡cticos
â”œâ”€â”€ python/ â†’ Scripts y notebooks en Python
â”‚ â”œâ”€â”€ 01_intro/ â†’ IntroducciÃ³n a Python
â”‚ â”œâ”€â”€ 02_collections/ â†’ Listas, diccionarios, etc.
â”‚ â”œâ”€â”€ 03_pandas/ â†’ AnÃ¡lisis de datos con Pandas
â”‚ â”œâ”€â”€ 04_debugging/ â†’ SoluciÃ³n de errores
â”‚ â””â”€â”€ 05_projects/ â†’ Proyectos con Python
â”œâ”€â”€ postgres/ â†’ ConfiguraciÃ³n y uso de PostgreSQL
â”‚ â”œâ”€â”€ schemas/ â†’ Esquemas y creaciÃ³n de tablas
â”‚ â”œâ”€â”€ setup/ â†’ Scripts de instalaciÃ³n y configuraciÃ³n
â”‚ â””â”€â”€ connections_pgadmin/â†’ ConexiÃ³n y gestiÃ³n desde pgAdmin
â”œâ”€â”€ spark/ â†’ Uso de Apache Spark y PySpark
â”‚ â”œâ”€â”€ 01_spark_sql/
â”‚ â”œâ”€â”€ 02_dataframe_api/
â”‚ â”œâ”€â”€ 03_transformations/
â”‚ â””â”€â”€ 04_hadoop_cluster/
â”œâ”€â”€ gcp/ â†’ Uso de Google Cloud Platform
â”‚ â”œâ”€â”€ setup/ â†’ Entorno e instalaciÃ³n
â”‚ â””â”€â”€ databricks/ â†’ Uso de Databricks en GCP
â”œâ”€â”€ screenshots/ â†’ Capturas de pgAdmin y otras herramientas
â”‚ â””â”€â”€ pgadmin/
â”œâ”€â”€ notes/ â†’ Apuntes personales y documentaciÃ³n




---

## ğŸ§  Habilidades desarrolladas

- Fundamentos de SQL para anÃ¡lisis e ingenierÃ­a de datos
- Escritura de queries optimizadas y troubleshooting
- ConfiguraciÃ³n de bases de datos PostgreSQL y uso de pgAdmin
- ProgramaciÃ³n en Python aplicada a pipelines y manipulaciÃ³n de datos
- Uso de Pandas y colecciones para procesamiento de datos
- Manejo de Apache Spark y PySpark para procesamiento distribuido
- ImplementaciÃ³n de entornos en GCP y Databricks

---

## ğŸš€ Objetivo del repositorio

Documentar de manera profesional mi avance en el curso y demostrar competencias en herramientas clave para la ingenierÃ­a de datos.
